{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing, visualising, and transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction  \n",
    "\n",
    "We will explore how to analyse and preprocess a numeric/tabular dataset to gain meaningful insights before applying machine learning models. Understanding your data is a crucial first step in any data science workflow, as it influences how well your models perform and generalise to unseen data. As you'll see, Data Science and Machine Learning are closely coupled.\n",
    "\n",
    "We will cover three key aspects of data exploration and preparation:  \n",
    "\n",
    "- *Describing the dataset* – We will generate statistical summaries, such as measures of central tendency (mean, median) and dispersion (variance, standard deviation), to understand the distribution of each feature. Additionally, we will examine missing values, outliers, and correlations between variables to identify patterns and potential preprocessing steps.  \n",
    "\n",
    "- *Visualising the dataset* – Data visualisation helps us uncover hidden relationships, trends, and anomalies. We will use histograms, box plots, scatter plots, and correlation heatmaps to visually inspect distributions, detect skewness, and understand feature interactions.    \n",
    "\n",
    "After working through this practical, you will have a structured approach to exploring, visualising, and preparing numeric data for analysis. This process is essential for making informed decisions in machine learning, as the quality of your input data directly impacts model accuracy and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install pandas seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "\n",
    "Descriptive statistics help us quickly understand what our data looks like. Instead of going through thousands of individual numbers, we can use these summaries to spot patterns, unusual values, and check whether the data behaves in the way we expect.\n",
    "\n",
    "Descriptive statistics are important in data analysis because they help us:\n",
    "\n",
    "- *Summarise large amounts of data simply*: Rather than examining every single value, we can look at averages and ranges to get a clear overview.\n",
    "\n",
    "- *Spot problems with the data*: By checking things like the average, spread, and typical values, we can find missing information, strange results, or mistakes in the data.\n",
    "\n",
    "- *Understand how the data is spread out*: Looking at the shape of the data helps us see if most values are similar or if there’s a big range. It also shows whether the data follows common patterns, like a bell curve (normal distribution).\n",
    "\n",
    "- *Identify unusual or extreme values*: Very high or low numbers might be errors or rare events that we need to pay attention to before using the data in models.\n",
    "\n",
    "- *Prepare the data for further analysis*: Knowing how the data behaves helps us decide what changes we might need to make—like adjusting values or removing features—to improve the results of our analysis or machine learning models.\n",
    "\n",
    "When we use descriptive statistics, we make sure our dataset is tidy and easy to work with, which helps us make better decisions during analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pima Indians dataset\n",
    "This dataset contains medical records for Pima Indians, along with a binary variable indicating whether or not each patient developed diabetes within five years.\n",
    "\n",
    "It is a classification problem with the following numeric features:\n",
    "1. Number of times pregnant.\n",
    "2. Plasma glucose concentration (2 hours in an oral glucose tolerance test).\n",
    "3. Diastolic blood pressure (mm Hg).\n",
    "4. Triceps skin fold thickness (mm).\n",
    "5. 2-Hour serum insulin (mu U/ml).\n",
    "6. Body mass index (BMI).\n",
    "7. Diabetes pedigree function.\n",
    "8. Age (years).\n",
    "9. Class (onset of diabetes within five years: 0 or 1).\n",
    "\n",
    "Let us download and load the dataset and begin exploring it further:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/martyn-harris-bbk/AppliedMachineLearning/main/data/pima-indians-diabetes.data.csv'\n",
    "\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "\n",
    "header = [\n",
    "    'Pregnancy_Count',\n",
    "    'Glucone_conc',\n",
    "    'Blood_pressure',\n",
    "    'Skin_thickness',\n",
    "    'Insulin',\n",
    "    'BMI',\n",
    "    'DPF',\n",
    "    'Age',\n",
    "    'Class'\n",
    "]\n",
    "\n",
    "data = pd.read_csv(filename, names=header)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we can see the dataset’s shape and the first few rows of data, confirming it has loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical summary\n",
    "\n",
    "Descriptive statistics help us understand how each part of a dataset is spread out. When we run `.describe()` on a pandas DataFrame in Python, we get a helpful summary that includes:\n",
    "\n",
    "- *Count* – Tells us how many values are present (not missing) for each column. This helps us spot any gaps in the data.\n",
    "\n",
    "- *Mean* – The average value. This gives us a rough idea of what’s “typical” for each column.\n",
    "\n",
    "- *Standard Deviation* – Shows how much the values vary. A high number means the data is more spread out.\n",
    "\n",
    "- *Minimum Value* – The smallest number in the column. This can help us find any errors or outliers.\n",
    "\n",
    "- *25th Percentile (Q1)* – A quarter of the values fall below this point. It gives us a sense of the lower end of the data.\n",
    "\n",
    "- *50th Percentile (Median/Q2)* – The middle value when the data is sorted. This shows us the centre of the data.\n",
    "\n",
    "- *75th Percentile (Q3)* – Three-quarters of the data fall below this point. It helps us understand the upper range.\n",
    "\n",
    "- *Maximum Value* – The largest value in the column. This can highlight extreme values or mistakes.\n",
    "\n",
    "These summaries make it easier to spot missing information, unusual results, or parts of the data that might need special attention—like features with a very wide range of values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution (for classification tasks)\n",
    "\n",
    "When you're working on a classification problem, it's important to check how evenly the different groups (or “classes”) are represented in your data.\n",
    "\n",
    "If one group has a lot more examples than another, your model may become *biased* towards the larger group. That means it might learn to predict the more common class more often, simply because it sees it more during training. As a result, it could perform very poorly on the smaller, less frequent class—completely missing important patterns or failing to spot rare but critical cases.\n",
    "\n",
    "This kind of imbalance can be a real issue, especially in areas like medical diagnoses, fraud detection, or safety systems, where the minority class is often the most important one to get right.\n",
    "\n",
    "Bias in machine learning isn’t just a technical problem—it can have real-world consequences. \n",
    "\n",
    "For example:\n",
    "\n",
    "> A study found that some facial recognition systems were significantly less accurate at identifying Black women compared to white men. This was largely because the training data contained far more images of lighter-skinned males. As a result, the system performed well on faces it had seen more often, but poorly on others, leading to unfair and potentially harmful outcomes.  \n",
    ">\n",
    "> [Read the study: *Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification* (Buolamwini & Gebru, 2018)](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf)\n",
    "\n",
    "\n",
    "Addressing class imbalance helps the model learn more fairly and make better, more reliable predictions for *all* groups in your data—not just the most common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data.groupby('Class').size()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are nearly twice as many instances of one class as the other. This moderate imbalance might still be okay, but it’s important to keep in mind when training models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "Correlation helps us understand whether two things are connected—and if so, how strongly.\n",
    "\n",
    "For example, think about ice cream sales and the weather. On hot days, people tend to buy more ice cream, right? That’s a *positive correlation*—as the temperature goes up, so do ice cream sales.\n",
    "\n",
    "Now imagine something like ice cream sales and rainy days. You might find that sales drop when it rains—that would be a *negative correlation*.\n",
    "\n",
    "If there’s *no clear pattern* between two things (like shoe size and how many cups of tea someone drinks), the correlation would be close to zero.\n",
    "\n",
    "In data analysis, we can use a simple command called `.corr()` in Python to check these kinds of relationships between different columns in our dataset. It gives us a number between -1 and 1 to show the strength and direction of the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = data.corr(method='pearson')\n",
    "\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look out for correlation values close to 1.0 or -1.0—these suggest a strong relationship between two variables. If two columns are very strongly linked, they might be telling you almost the same thing. In that case, you may not need to keep both, as it could add unnecessary repetition to your analysis or confuse your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew\n",
    "\n",
    "Skew tells us how *symmetrical* our data is—or in simple terms, whether it leans to one side. Ideally, many datasets follow a “normal” or *bell-shaped* curve, where most values sit around the middle, and there are fewer values at the low and high ends. This is called a *normal distribution*.\n",
    "\n",
    "But real-world data is often not so neat. That’s where *skew* comes in:\n",
    "\n",
    "- A *skew close to 0* means the data is fairly balanced—no strong lean to either side.\n",
    "- A *positive skew* (right-skewed) means the tail of the data stretches out to the right. This happens when there are a few much larger values than the rest—for example, with salaries in a company where a handful of executives earn far more than everyone else.\n",
    "- A *negative skew* (left-skewed) means the tail stretches out to the left. This happens when a few values are *much lower* than the rest. For example, imagine you're looking at the age at which people retire. Most people might retire around 65, but a small number retire much earlier—maybe in their 40s or 50s—because of early pensions or financial independence. Those few very early retirements pull the distribution to the left, creating a *negative skew*.\n",
    "\n",
    "Why does skew matter? Because many analysis tools and machine learning models assume your data is roughly symmetrical (normally distributed). If it’s heavily skewed, those assumptions might break down, leading to misleading results. \n",
    "\n",
    "In that case, you might need to adjust the data using techniques like log transformations or other methods to bring it closer to a normal shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = data.skew()\n",
    "\n",
    "skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see which attributes are skewed and might benefit from transformations (e.g., log transform)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "Visualisations are one of the most powerful tools in data analysis. They allow you to *see* patterns, trends, and problems in your data that might be hard to spot just by looking at numbers in a table. With just a few simple plots, you can quickly get a feel for how your data is distributed, whether there are any outliers, and how different variables relate to each other.\n",
    "\n",
    "There are two main types of visualisations you’ll use when working with numeric data: *univariate* and *multivariate* plots.\n",
    "\n",
    "### Univariate Plots\n",
    "\n",
    "*Univariate* means “one variable.” These types of plots help you understand the distribution of a single column or feature in your dataset. You might use univariate plots to answer questions like:  \n",
    "- Are most values clustered in one range?  \n",
    "- Are there extreme values (outliers)?  \n",
    "- Is the data skewed to one side?\n",
    "\n",
    "Common univariate plots include:  \n",
    "- *Histograms* – show how values are spread out over intervals  \n",
    "- *Box plots* – highlight the median, quartiles, and outliers  \n",
    "- *Density plots* – give a smoothed version of a histogram\n",
    "\n",
    "These are great for spotting skew, checking for missing data, or deciding whether you might need to transform or clean a feature.\n",
    "\n",
    "### Multivariate Plots\n",
    "\n",
    "*Multivariate* means “more than one variable.” These plots help you explore relationships between two or more features in your data. They can show you things like:  \n",
    "- Do two features rise or fall together (correlation)?  \n",
    "- Are there patterns that depend on more than one factor?  \n",
    "- Are certain values more common for specific groups?\n",
    "\n",
    "Useful multivariate plots include:  \n",
    "- *Scatter plots* – show the relationship between two numerical features  \n",
    "- *Pair plots* – show scatter plots for many variable combinations in one grid  \n",
    "- *Heatmaps* – often used to show correlation between features  \n",
    "- *Coloured or faceted plots* – allow you to add a third variable using colour or small multiples (e.g. scatter plot coloured by category)\n",
    "\n",
    "These plots are especially useful when you're preparing data for machine learning, as they can highlight which features are likely to be useful for prediction, and which might be redundant or highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate plots\n",
    "\n",
    "#### Histograms\n",
    "\n",
    "A *histogram* is a simple but powerful way to understand how your data is distributed. It works by dividing the range of values into equal-sized groups, called *bins*, and then showing how many data points fall into each one.\n",
    "\n",
    "Think of it like sorting test scores into grade bands—0–10, 10–20, 20–30, and so on—and then counting how many people scored within each band.\n",
    "\n",
    "Histograms help answer questions like:\n",
    "- Are most values close together or spread out?\n",
    "- Does the data have one clear peak (called a *mode*) or several?\n",
    "- Are there any gaps or outliers?\n",
    "- Is the distribution symmetrical, or is it skewed to one side?\n",
    "\n",
    "For example, if you're looking at people’s ages, a histogram can quickly show whether most people fall into a certain age group, or if the ages are spread fairly evenly across the range.\n",
    "\n",
    "Histograms are especially useful for:\n",
    "- Getting a quick sense of the shape of your data\n",
    "- Identifying skew (leaning to the left or right)\n",
    "- Spotting unusual values or unexpected patterns\n",
    "\n",
    "Unlike bar charts (which are used for categorical data), histograms are for *numerical* data and display a continuous range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=[20, 20])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density Plots\n",
    "\n",
    "A density plot is a smooth, curved version of a histogram. Instead of showing bars to count how many data points fall into each bin, it draws a continuous curve that shows where the values in your data are concentrated.\n",
    "\n",
    "You can think of it like gently draping a smooth sheet over a histogram—it gives you a clearer picture of the *shape* of the data without the blocky steps of bars.\n",
    "\n",
    "Density plots help answer similar questions to histograms, such as:\n",
    "- Where are most of the values grouped?\n",
    "- Is the data symmetrical or skewed?\n",
    "- Are there one or more peaks (modes) in the data?\n",
    "\n",
    "They are especially useful when you want:\n",
    "- A cleaner, more polished view of your data distribution\n",
    "- To compare multiple groups or datasets on the same graph\n",
    "- To spot subtle patterns that might be hidden in a histogram\n",
    "\n",
    "For example, if you wanted to compare the test scores of two different classes, you could plot both curves on the same chart. You’d instantly see which group performed better, whether one group was more spread out, or if both had similar results.\n",
    "\n",
    "Unlike histograms, which depend on how the bins are set up, density plots aren’t affected by the number or width of bins—making them a more flexible and visually appealing option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='density', subplots=True, layout=(3,3), sharex=False, figsize=[20, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box and Whisker Plots\n",
    "\n",
    "A *box and whisker plot* (often just called a *box plot*) is a simple way to show how values in a dataset are spread out. It gives you a quick visual summary of key statistics, such as the middle of the data, how spread out it is, and whether there are any unusual values.\n",
    "\n",
    "Each box plot shows:\n",
    "- The *median* (the middle value)\n",
    "- The *lower* and *upper quartiles* (the values that separate the lowest 25% and highest 25% of the data)\n",
    "- The *“whiskers”*, which show the overall spread of most of the data\n",
    "- *Outliers*, which are individual points that fall far outside the rest of the data\n",
    "\n",
    "You can use box plots to:\n",
    "- Compare distributions across different groups\n",
    "- Spot outliers quickly\n",
    "- See whether the data is symmetrical or skewed\n",
    "\n",
    "For example, imagine you're comparing the daily commute times for people in four different cities. A box plot for each city would let you quickly see which city has the longest or shortest typical journey, which one has the most variation, and whether any cities have a few people with extremely long or short travel times.\n",
    "\n",
    "Box plots are especially useful when you want to compare many features or groups side by side without cluttering the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=[20, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional visualisations\n",
    "\n",
    "#### Violin Plots\n",
    "\n",
    "A *violin plot* combines the best parts of a *box plot* and a *density plot* into one visual. It not only shows key statistics like the *median* and *quartiles*, but also gives you a smooth curve that shows the *shape* of the data—where values are more or less concentrated.\n",
    "\n",
    "You can think of it like a mirrored density plot with a box plot in the middle. The wider parts of the violin shape show where more data points are clustered, and the thinner parts show where data is sparse.\n",
    "\n",
    "Violin plots are especially useful when you want to:\n",
    "- *Compare the full distribution of values across different groups*  \n",
    "- *Spot skew, multimodal patterns (more than one peak), or outliers*  \n",
    "- *Get a clearer sense of the spread than a box plot alone can offer*\n",
    "\n",
    "For example, if you're looking at customer ratings for different food delivery apps, a violin plot could show how those ratings are spread for each one. You might see that one app consistently gets high ratings clustered around 4.5 stars, while another has a wider spread—suggesting that users have more mixed experiences.\n",
    "\n",
    "This type of plot gives more detail than a simple average or box plot and can help you make better-informed comparisons between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "numeric_cols = ['Pregnancy_Count','Glucone_conc','Blood_pressure','Skin_thickness','Insulin','BMI','DPF','Age']\n",
    "sns.violinplot(data=data[numeric_cols], orient='h')\n",
    "plt.title('Violin Plots of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Plots\n",
    "\n",
    "*Multivariate plots* help you explore the relationships between two or more variables at the same time. They’re especially useful for spotting trends, clusters, or patterns that might not be obvious when looking at one variable on its own.\n",
    "\n",
    "These plots are key when you want to understand how features interact or when preparing data for machine learning models.\n",
    "\n",
    "#### Correlation Matrix Plot\n",
    "\n",
    "A *correlation matrix plot* shows how strongly each pair of variables is related, using colours in a *heatmap* to represent the correlation coefficients.\n",
    "\n",
    "Each cell in the matrix shows a value between -1 and 1:\n",
    "- *1* means a perfect positive relationship (as one goes up, so does the other)  \n",
    "- *-1* means a perfect negative relationship (as one goes up, the other goes down)  \n",
    "- *0* means no clear relationship between the two\n",
    "\n",
    "These plots help you:\n",
    "- *Quickly identify strong positive or negative relationships*  \n",
    "- *Spot features that may be redundant (highly correlated)*  \n",
    "- *Decide which variables might be useful in a model*\n",
    "\n",
    "For example, in a dataset about housing, you might see a strong positive correlation between house size and price, and a negative correlation between distance to the city centre and price. A correlation matrix makes these patterns easy to see at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = data.corr()\n",
    "\n",
    "fig = plt.figure(figsize=[10, 10])\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ticks = np.arange(0,9,1)\n",
    "\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "\n",
    "short_names = ['#Preg','Gluco','BloodP','Skin_Th','Insulin','BMI','DPF','Age','Class']\n",
    "\n",
    "ax.set_xticklabels(short_names)\n",
    "ax.set_yticklabels(short_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a simpler version without custom tick labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10, 10])\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "\n",
    "fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Plot Matrix\n",
    "\n",
    "A *scatter plot matrix* (also called a *pair plot*) is a grid of scatter plots that shows how each pair of numerical features in your dataset relates to one another.\n",
    "\n",
    "Each cell in the grid is a scatter plot that compares two different features. This makes it easy to spot patterns, trends, or clusters that might not be visible when looking at just one or two features on their own. Scatter plot matrices are useful for:\n",
    "- *Visualising relationships between many features at once*  \n",
    "- *Detecting linear or non-linear trends*  \n",
    "- *Identifying clusters or groupings in the data*  \n",
    "- *Spotting outliers that don’t follow the general pattern*\n",
    "\n",
    "For example, if you're analysing data from a fitness tracker, a scatter plot matrix might show that *step count* and *calories burned* are positively related (as one increases, so does the other), while *sleep duration* might decrease as *daily Netflix time* goes up. These kinds of patterns can help you understand how lifestyle habits interact.\n",
    "\n",
    "These plots can become quite large if your dataset has many features, but they’re very helpful for getting an overall sense of how your variables behave together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.plotting.scatter_matrix(data, figsize=[20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair Plot (Seaborn)\n",
    "\n",
    "A *pair plot* is similar to a *scatter plot matrix*, but with some extra helpful features. It's especially useful when using the Seaborn library in Python. In addition to showing scatter plots for every pair of numerical features, a pair plot can:\n",
    "- *Colour the data points by category or class* (e.g. product type, user group, or outcome)\n",
    "- *Include histograms or density curves along the diagonal* to show the distribution of individual features\n",
    "\n",
    "This makes it easier to spot patterns or groupings that depend on categories in your data.\n",
    "\n",
    "For example, if you're analysing wearable fitness data, a pair plot could compare things like *steps per day*, *active minutes*, and *sleep duration*, while colouring the points based on *activity level* (e.g. low, medium, high). You might notice that people with higher activity levels also tend to sleep more or have more consistent step counts.\n",
    "\n",
    "Pair plots are a great tool for getting a quick, all-in-one view of how multiple features interact, especially when categories are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue='Class')\n",
    "\n",
    "plt.suptitle('Pairwise Relationships with Seaborn PairPlot', y=1.02)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution Plots\n",
    "\n",
    "*Distribution plots* show how the values of a single variable are spread out across a range. They help you see where most of the data points fall, and whether the values are concentrated, evenly spread, or skewed in one direction.\n",
    "\n",
    "These plots often include:\n",
    "- *Bars* to show how many values fall within certain ranges (like a histogram)  \n",
    "- *A smooth curve* to highlight the overall shape of the data (like a density plot)\n",
    "\n",
    "Distribution plots are useful for:\n",
    "- *Understanding the general shape of your data*  \n",
    "- *Spotting any unusual peaks or gaps*  \n",
    "- *Seeing whether values are grouped around a central point or spread out*  \n",
    "\n",
    "For example, if you’re looking at daily screen time across a group of people, a distribution plot can reveal whether most people use their devices for around the same amount of time, or if some people use them much more or less than others.\n",
    "\n",
    "These plots are great for quickly getting a feel for a single feature and are often used early in data analysis to spot potential issues or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "    sns.histplot(data[col], kde=True)\n",
    "    \n",
    "plt.title(f\"Distribution of features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What have we learnt?\n",
    "\n",
    "Visualisation helps us understand what transformations are doing — plots like histograms, box plots, and scatter matrices can reveal whether a transformation has improved the data's structure.\n",
    "\n",
    "In this practical, we explored how to understand and prepare a tabular dataset before applying any machine learning models. When we combined descriptive statistics and visualisation techniques, we gained valuable insights into the structure, distribution, and relationships within the data. Here’s a summary of what we discussed:\n",
    "\n",
    "- *Describing the dataset*: We used statistical summaries (like mean, median, and standard deviation) to get a quick overview of each feature. This helped us spot issues such as missing values, outliers, and unusual distributions.\n",
    "\n",
    "- *Visualising the dataset*: Using histograms, density plots, box plots, and violin plots, we explored how each feature is distributed. We also used correlation heatmaps, scatter matrix plots, and pair plots to examine how features interact with one another.\n",
    "\n",
    "- *Understanding data quality*: When looking at class imbalance and skew, we identified areas that might require transformation or careful handling during model training.\n",
    "\n",
    "- *The importance of preprocessing*: These steps are critical for preparing data in a way that helps machine learning models learn more effectively and fairly. Good data understanding leads to better feature selection, more robust models, and more accurate results.\n",
    "\n",
    "Altogether, these techniques provide a solid foundation for responsible and effective data analysis, helping us make informed decisions before modelling begins."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
