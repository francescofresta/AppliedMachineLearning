{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNjbleaNrsOR"
      },
      "source": [
        "# Numeric data for Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndyo4BqnrsOT"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Being able to load your data is a fundamental first step in practically any machine learning project. The most common file format for such data is CSV (Comma-Separated Values). Python provides multiple ways to handle CSV files. Below are three standard approaches:\n",
        "\n",
        "1. Loading CSV files using the python standard library (`csv` module).\n",
        "2. Loading CSV files using NumPy (via `numpy.loadtxt` or `numpy.genfromtxt`).\n",
        "3. Loading CSV files using pandas (via `pandas.read_csv`).\n",
        "\n",
        "Each approach has different strengths:\n",
        "- **Python standard library**: No external dependencies, but you need to parse or convert types manually.\n",
        "- **NumPy**: Good for large numeric datasets, but might require manual handling of headers or text.\n",
        "- **pandas**: Very flexible, automatically handles many typical data-loading tasks, supports numerous parameters for parsing complex CSV files, and creates a powerful `DataFrame` object that simplifies subsequent data analysis.\n",
        "\n",
        "As a reference, you can learn a lot about CSV formatting conventions by reviewing the request for comment titled [Common Format and MIME Type for Comma-Separated Values (CSV) Files (RFC 4180)](https://tools.ietf.org/html/rfc4180).\n",
        "\n",
        "Below are some points to keep in mind when working with CSV files:\n",
        "\n",
        "**File header**:\n",
        "- Does your CSV have a header row that labels each column? If yes, you can instruct your loading function to interpret the first row as the header. Otherwise, you may have to provide your own list of column names.\n",
        "\n",
        "**Comments**:\n",
        "- Some CSV files contain comment lines, typically starting with `#`. Depending on the method you use, you may need to specify that your file has comment lines or define which character is used to mark them.\n",
        "\n",
        "**Delimiter**:\n",
        "- The comma (`,`) is the default field delimiter for CSV files, but your data may use tabs (`\\t`) or other delimiters (e.g., `;`). Make sure you specify the correct delimiter if it differs from the default.\n",
        "\n",
        "**Quotes**:\n",
        "- Fields in a CSV may include spaces or other special characters. Such fields are often enclosed in quotes (by default `\"`). If your file uses a different quote character, you must specify it to ensure the data is parsed correctly.\n",
        "\n",
        "Understanding these aspects of your CSV file helps avoid errors and ensures the data is loaded consistently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4btreo35rsOU"
      },
      "source": [
        "### Installing Python libraries\n",
        "One great feature about jupyter notebooks is that we can run terminal commands. This means we can install python libraries on the fly, using the `!` prefix. If you plan on running these notebooks on your own machine, you'll need to install a few libraries as and when they are required. Below is an example specifically installing `pandas` and `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU2vdiBkbKBE",
        "outputId": "2a5d988d-0697-4758-c8b5-49101fbb6521"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "\n",
        "!pip install pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNhuhRjlrsOU"
      },
      "source": [
        "## Pima Indians dataset\n",
        "\n",
        "Throughout this notebook, we will use the **Pima Indians dataset** to demonstrate how to load data into python. This dataset describes medical records for Pima Indians, indicating whether or not each patient develops diabetes within five years.\n",
        "\n",
        "The Pima Indian diabetes dataset is a renowned benchmark in the field of machine learning. It was originally made available through the *National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK)* in the United States, and later hosted on the *UCI Machine Learning Repository*. Over time, it has become a standard reference dataset for illustrating and evaluating classification algorithms.\n",
        "\n",
        "### Who was studied\n",
        "\n",
        "- The dataset focuses on adult female patients (aged 21 or older) of Pima Indian heritage residing near Phoenix, Arizona.  \n",
        "- This population is known to have a significantly higher incidence of type 2 diabetes.\n",
        "\n",
        "### What was measured\n",
        "\n",
        "Each entry in the dataset corresponds to one participant and includes **8 numerical attributes** capturing medical and demographic information:\n",
        "\n",
        "1. **Number of times pregnant** (often referred to as “pregnancies”).  \n",
        "2. **Plasma glucose concentration** (after a 2-hour oral glucose tolerance test).  \n",
        "3. **Diastolic blood pressure** (mm Hg).  \n",
        "4. **Triceps skin fold thickness** (mm).  \n",
        "5. **2-hour serum insulin** (mu U/ml).  \n",
        "6. **Body mass index (BMI)**.  \n",
        "7. **Diabetes pedigree function (DPF)** – an indication of diabetes likelihood based on familial and genetic risk.  \n",
        "8. **Age** (years).\n",
        "\n",
        "In addition, each record contains a **binary outcome** (“class”) indicating whether or not the participant developed **type 2 diabetes** within five years.\n",
        "\n",
        "### Why it was collected\n",
        "\n",
        "Researchers aimed to investigate risk factors for diabetes among a group with a particularly high risk of the disease. Various medical and demographic data (such as glucose tolerance tests, insulin measurements, and age) were gathered to determine which factors most strongly predicted the onset of diabetes.\n",
        "\n",
        "### How the data was obtained\n",
        "\n",
        "1. **Patient recruitment**  \n",
        "   Eligible participants were female Pima Indians, aged 21 or older.  \n",
        "\n",
        "2. **Measurements and testing**  \n",
        "   Each participant underwent standard medical tests, including measuring plasma glucose concentration, blood pressure, and insulin levels, alongside providing demographic details such as age and number of pregnancies.  \n",
        "\n",
        "3. **Five-year follow-up**  \n",
        "   The pivotal outcome was whether each participant experienced the onset of type 2 diabetes within five years. This information was determined through follow-up medical records and diagnoses.  \n",
        "\n",
        "4. **Compilation**  \n",
        "   The anonymised data were assembled into a structured dataset of 768 entries, each representing a single participant’s measurements and diabetes outcome (onset or no onset).\n",
        "\n",
        "The Pima Indian diabetes dataset remains a pivotal resource for demonstrating fundamental classification techniques and exploring how demographic and medical attributes can help predict the onset of type 2 diabetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaQzlJLeWoHL"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qwv_0ynWsXC",
        "outputId": "6c871314-c6c3-4108-b1b2-5eafcc5c03ab"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/martyn-harris-bbk/AppliedMachineLearning/main/data/pima-indians-diabetes.data.csv'\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "print(\"Download complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkvWy8amrsOW"
      },
      "source": [
        "### Load csv from file\n",
        "\n",
        "In the code cell above, we demonstrate how to read a CSV file from your local system. We do this by providing the file path in the `filename` variable, and specifying a list of column names (`header`). If your CSV already contains a header row, you could set `header=0` (or omit the `names=` parameter entirely) to tell pandas to use the first row of the file as the header.\n",
        "\n",
        "The `.read_csv()` function returns a `pandas.DataFrame` object, which is a powerful 2D data structure that allows row and column operations, descriptive statistics, and data manipulations. You can immediately start summarising and visualising the data using DataFrame methods such as `.describe()`, `.head()`, `.plot()`, and so on.\n",
        "\n",
        "For more information on `pandas.DataFrame`, see the [API documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEJxb5ADrsOW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "\n",
        "header = [\n",
        "    'Pregnancy_Count',\n",
        "    'Glucone_conc',\n",
        "    'Blood_pressure',\n",
        "    'Skin_thickness',\n",
        "    'Insulin',\n",
        "    'BMI',\n",
        "    'DPF',\n",
        "    'Age',\n",
        "    'Class'\n",
        "]\n",
        "\n",
        "data = pd.read_csv(filename, names=header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWLpVqwIrsOW"
      },
      "source": [
        "### Load csv using pandas from url\n",
        "\n",
        "In many cases, you may want to load CSV data directly from a web resource. Below, we show you how to modify the example to read the Pima Indians data from a GitHub URL, without having to download it locally first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8uOWfBZrsOX"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/martyn-harris-bbk/AppliedMachineLearning/main/data/pima-indians-diabetes.data.csv'\n",
        "header = ['Pregnancy_Count','Glucone_conc','Blood_pressure','Skin_thickness','Insulin','BMI','DPF','Age','Class']\n",
        "\n",
        "data = pd.read_csv(url, names=header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuogQrMqrsOX"
      },
      "source": [
        "# Viewing our data\n",
        "\n",
        "After successfully loading a dataset into a `DataFrame`, a critical next step is to inspect the structure of the data. We often want to do a quick sanity check to make sure the columns are parsed correctly and the data types match our expectations.\n",
        "\n",
        "One quick way to do this is by using the `data.head()` function, which shows the first 5 rows of the DataFrame by default. This lets you see if each column is in the correct position and whether the data values look reasonable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_Ow_DsyDrsOX",
        "outputId": "ae58b478-e297-4869-94e9-bea73902c812"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In7fBVPlrsOX"
      },
      "source": [
        "By default, `head()` returns 5 rows, but you can specify exactly how many rows you want to preview by passing an integer. For example, `data.head(20)` will show the first 20 rows.\n",
        "\n",
        "Previewing just the first few rows is extremely helpful for verifying that the data has been read in correctly, especially if you suspect issues with delimiters, headers, or quoting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "8x2Cr0mbrsOX",
        "outputId": "57e0cba5-4e9a-45c9-f4a0-a5a039e64787"
      },
      "outputs": [],
      "source": [
        "data.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVQXQ7A4rsOX"
      },
      "source": [
        "Similarly, `data.tail()` returns the last few rows of the DataFrame. This can help you inspect how data is structured near the end of the file and confirm if the file terminates properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-25pdt1OrsOX",
        "outputId": "1394ed55-87f0-4ef0-f9be-2d130d370758"
      },
      "outputs": [],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zw6XMGtrsOX"
      },
      "source": [
        "# What is the dimensionality of our data?\n",
        "\n",
        "We generally want to know the overall shape of the data (i.e., how many rows and columns). The `DataFrame.shape` attribute provides this as a tuple `(rows, columns)`.\n",
        "\n",
        "In machine learning contexts, the number of rows typically corresponds to the number of examples, and the number of columns represents your features (plus, optionally, a target column if included in the data). Knowing these figures is essential for planning data splitting, memory usage, and subsequent model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J6PWDSMrsOY",
        "outputId": "19122728-758a-4adb-e687-489e5c6689e5"
      },
      "outputs": [],
      "source": [
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67LvZQvorsOY"
      },
      "source": [
        "From the tuple returned, we can see that the Pima Indians dataset contains **768 rows** and **9 columns**. The 9 columns correspond to 8 explanatory features plus 1 target column (`Class`).\n",
        "\n",
        "This knowledge helps us ensure we have the complete dataset loaded. It's also a good initial check before we proceed to more in-depth data profiling or feature analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P37fViu6rsOY"
      },
      "source": [
        "## Exploring more details of the data\n",
        "\n",
        "Beyond checking the first few and last few rows, pandas offers convenient methods to quickly summarise your dataset. For instance, if you want to:\n",
        "\n",
        "- View column data types and any non-null counts, you can use `data.info()`. This can be useful to spot missing values or confirm that columns are numeric.\n",
        "- Get a statistical summary of your numeric columns, you can use `data.describe()`, which provides statistics such as mean, standard deviation, minimum, and maximum values.\n",
        "\n",
        "Let us look at some of these methods in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVuDY1PVrsOY",
        "outputId": "52e70c52-06f9-468f-9863-df81eaf9f962"
      },
      "outputs": [],
      "source": [
        "# Checking data info\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1HvwOnirsOY"
      },
      "source": [
        "From `data.info()`, you can see how many rows have non-null values in each column and the data type (`int64`, `float64`, `object`, etc.). This can highlight if some columns are missing data or are stored in unexpected types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHcgSHGsrsOY"
      },
      "source": [
        "### Getting a statistical summary of numerical columns\n",
        "\n",
        "Using `data.describe()`, you can quickly observe general statistics about each numeric column, such as:\n",
        "\n",
        "- **count**: The number of non-missing values.\n",
        "- **mean**: Average value.\n",
        "- **std**: Standard deviation, a measure of spread.\n",
        "- **min** and **max**: The lowest and highest value observed.\n",
        "- **25%**, **50%**, **75%**: The quartiles, which help you understand the distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "QS5h3t_nrsOY",
        "outputId": "fb6b5c22-5b4a-46e8-ec43-640250eb8878"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZHCKSphrsOY"
      },
      "source": [
        "These statistical measures are crucial for initial exploratory data analysis, which guides subsequent data cleaning, feature engineering, and model building. We will explore some of these statistical measures in more depth as we progress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMJTQ3RqrsOY"
      },
      "source": [
        "Here's the adapted version with the bulleted text in *italics* instead of **bold**:\n",
        "\n",
        "---\n",
        "\n",
        "## Recommended datasets\n",
        "\n",
        "Here are some widely used, freely available numeric datasets you might explore for practice:\n",
        "\n",
        "### Numeric datasets\n",
        "\n",
        "**Iris**  \n",
        "- *Description*: Classic dataset of 150 iris flowers with four features each (sepal length, sepal width, petal length, petal width) and three species of iris as the target.  \n",
        "- *Why it’s popular*: Very small (perfect for quick demos) and well-labelled, making it easy to visualise in 2D or 3D.  \n",
        "- *Where to get it*: Built into scikit-learn (`sklearn.datasets.load_iris`) or from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Iris).\n",
        "\n",
        "**Wine**  \n",
        "- *Description*: Chemical analysis of wines grown in the same region in Italy but from three different cultivars. Each sample has 13 numeric features.  \n",
        "- *Why it’s popular*: Good example for classification with multiple classes.  \n",
        "- *Where to get it*: Built into scikit-learn (`sklearn.datasets.load_wine`) or from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Wine).\n",
        "\n",
        "**Wine Quality**  \n",
        "- *Description*: Wine samples (red or white) with attributes such as acidity, sulphates, pH, and a quality rating.  \n",
        "- *Why it’s popular*: Demonstrates regression or classification.  \n",
        "- *Where to get it*: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Wine+Quality).\n",
        "\n",
        "**Adult**  \n",
        "- *Description*: Census data (48,842 instances) used for predicting whether an individual’s income exceeds $50K/year.  \n",
        "- *Why it’s popular*: Classification with categorical and numeric features, plus data-cleaning challenges.  \n",
        "- *Where to get it*: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult).\n",
        "\n",
        "**Titanic**  \n",
        "- *Description*: Passenger data about who survived/perished on the RMS Titanic.  \n",
        "- *Why it’s popular*: Classic Kaggle competition for beginners, with mixed feature types and missing data.  \n",
        "- *Where to get it*: [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
